[2025-09-17 19:47:15,871] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-17 19:47:19,666] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-09-17 19:47:20,422] [WARNING] [runner.py:220:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-09-17 19:47:20,423] [INFO] [runner.py:610:main] cmd = /home/victor/anaconda3/envs/nir/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None opt_deepspeed.py
[2025-09-17 19:47:22,559] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-17 19:47:25,629] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-09-17 19:47:26,296] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1]}
[2025-09-17 19:47:26,297] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=2, node_rank=0
[2025-09-17 19:47:26,297] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})
[2025-09-17 19:47:26,297] [INFO] [launch.py:164:main] dist_world_size=2
[2025-09-17 19:47:26,297] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1
[2025-09-17 19:47:26,297] [INFO] [launch.py:256:main] process 5449 spawned with command: ['/home/victor/anaconda3/envs/nir/bin/python', '-u', 'opt_deepspeed.py', '--local_rank=0']
[2025-09-17 19:47:26,300] [INFO] [launch.py:256:main] process 5450 spawned with command: ['/home/victor/anaconda3/envs/nir/bin/python', '-u', 'opt_deepspeed.py', '--local_rank=1']
[2025-09-17 19:47:30,073] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-17 19:47:30,098] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-17 19:47:34,645] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-09-17 19:47:34,655] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-09-17 19:47:34,690] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-09-17 19:47:34,696] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-09-17 19:47:34,696] [INFO] [comm.py:852:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
start benchmark
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
[2025-09-17 19:47:45,321] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.17.5, git-hash=unknown, git-branch=unknown
[2025-09-17 19:47:45,322] [INFO] [logging.py:107:log_dist] [Rank 0] [TorchCheckpointEngine] Initialized with serialization = False
[2025-09-17 19:47:45,322] [INFO] [logging.py:107:log_dist] [Rank 0] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[2025-09-17 19:47:45,397] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 2048, 'intermediate_size': 8192, 'heads': 32, 'num_hidden_layers': -1, 'dtype': torch.float32, 'pre_layer_norm': True, 'norm_type': <NormType.LayerNorm: 1>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 2, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.ReLU: 2>, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 1024, 'min_out_tokens': 1, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1, 'rope_theta': 10000, 'invert_mask': True}
Using /home/victor/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/victor/.cache/torch_extensions/py311_cu118/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Using /home/victor/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.03128933906555176 seconds
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.10743927955627441 seconds
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
------------------------------------------------------
Free memory : 4.594910 (GigaBytes)  
Total memory: 7.919250 (GigaBytes)  
Requested memory: 3.609375 (GigaBytes) 
Setting maximum total tokens (input + output) to 1024 
WorkSpace: 0x734c16000000 
------------------------------------------------------
stop benchmark
output: ["is curly maple a hardwood\nIt's a hardwood. It's a hardwood that's hard to cut.", 'what is gingerbread with architectural\n\nwhat is gingerbread with architectural\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural', 'automaticall start skype\n\nI have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a']
                     time  memory_gpu_0  ...  memory_gpu_1  max_memory_gpu_1
name                                     ...                                
start         7021.265890  4.768372e-07  ...  4.768372e-07          0.000003
generator     7040.131407  2.705656e+00  ...  2.705656e+00          2.705658
loop:0 start  7040.132858  2.705657e+00  ...  2.705657e+00          2.705659
loop:0 stop   7632.939443  2.713629e+00  ...  2.713629e+00          3.399961

[4 rows x 5 columns]
-------Benchmark results-------
model name: deepspeed_opt-1.3b
model size: 4.902, dtype: float32
mean inference time (s): 592.807
mean throughput (token/s): 4.750
num loops: 1, data size: 11, batch size: 11, max len: 64, max new tokens: 256
    inference time (s): 592.807
    throughput (token/s): 4.750

max memory allocated per device for generator (GB):            
    device 0: 2.706
    device 1: 2.706

max memory allocated per device for inference (GB):            
    device 0: 3.400
    device 1: 3.400

max memory allocated per device (GB):            
    device 0: 3.400
    device 1: 3.400
[2025-09-17 19:57:58,416] [INFO] [launch.py:351:main] Process 5450 exits successfully.
[2025-09-17 19:57:58,417] [INFO] [launch.py:351:main] Process 5449 exits successfully.
