[2025-09-17 19:58:02,671] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-17 19:58:05,864] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-09-17 19:58:06,549] [WARNING] [runner.py:220:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-09-17 19:58:06,549] [INFO] [runner.py:610:main] cmd = /home/victor/anaconda3/envs/nir/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None opt_single.py
[2025-09-17 19:58:08,615] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-17 19:58:11,708] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-09-17 19:58:12,370] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1]}
[2025-09-17 19:58:12,370] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=2, node_rank=0
[2025-09-17 19:58:12,370] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})
[2025-09-17 19:58:12,370] [INFO] [launch.py:164:main] dist_world_size=2
[2025-09-17 19:58:12,370] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1
[2025-09-17 19:58:12,371] [INFO] [launch.py:256:main] process 5773 spawned with command: ['/home/victor/anaconda3/envs/nir/bin/python', '-u', 'opt_single.py', '--local_rank=0']
[2025-09-17 19:58:12,373] [INFO] [launch.py:256:main] process 5774 spawned with command: ['/home/victor/anaconda3/envs/nir/bin/python', '-u', 'opt_single.py', '--local_rank=1']
[2025-09-17 19:58:16,188] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-17 19:58:16,247] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-17 19:58:20,819] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-09-17 19:58:20,827] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-09-17 19:58:20,827] [INFO] [comm.py:852:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-09-17 19:58:20,946] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-09-17 19:58:20,953] [INFO] [comm.py:821:init_distributed] cdb=None
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
start benchmark
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
stop benchmark
output: ["is curly maple a hardwood\nIt's a hardwood. It's a hardwood that's hard to cut.", 'what is gingerbread with architectural\n\nwhat is gingerbread with architectural\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural?\n\nWhat is Gingerbread with Architectural', 'automaticall start skype\n\nI have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a problem with my skype. I have a']
                     time  memory_gpu_0  ...  memory_gpu_1  max_memory_gpu_1
name                                     ...                                
start         7666.654450  4.768372e-07  ...  4.768372e-07          0.000003
generator     7673.772254  4.901582e+00  ...  4.901582e+00          4.901585
loop:0 start  7673.773503  4.901583e+00  ...  4.901583e+00          4.901586
loop:0 stop   8131.558548  4.910410e+00  ...  4.910410e+00          5.596484

[4 rows x 5 columns]
-------Benchmark results-------
model name: deepspeed_single-1.3b
model size: 4.902, dtype: float32
mean inference time (s): 457.785
mean throughput (token/s): 6.151
num loops: 1, data size: 11, batch size: 11, max len: 64, max new tokens: 256
    inference time (s): 457.785
    throughput (token/s): 6.151

max memory allocated per device for generator (GB):            
    device 0: 4.902
    device 1: 4.902

max memory allocated per device for inference (GB):            
    device 0: 5.596
    device 1: 5.596

max memory allocated per device (GB):            
    device 0: 5.596
    device 1: 5.596
[2025-09-17 20:06:16,578] [INFO] [launch.py:351:main] Process 5774 exits successfully.
[2025-09-17 20:06:16,578] [INFO] [launch.py:351:main] Process 5773 exits successfully.
