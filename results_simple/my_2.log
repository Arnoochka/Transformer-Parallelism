[2025-09-20 14:22:24,345] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-20 14:22:27,547] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-09-20 14:22:28,217] [WARNING] [runner.py:220:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-09-20 14:22:28,218] [INFO] [runner.py:610:main] cmd = /home/victor/anaconda3/envs/nir/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None opt_my.py
[2025-09-20 14:22:30,289] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-20 14:22:33,379] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-09-20 14:22:34,054] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1]}
[2025-09-20 14:22:34,055] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=2, node_rank=0
[2025-09-20 14:22:34,055] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})
[2025-09-20 14:22:34,055] [INFO] [launch.py:164:main] dist_world_size=2
[2025-09-20 14:22:34,055] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1
[2025-09-20 14:22:34,055] [INFO] [launch.py:256:main] process 6805 spawned with command: ['/home/victor/anaconda3/envs/nir/bin/python', '-u', 'opt_my.py', '--local_rank=0']
[2025-09-20 14:22:34,057] [INFO] [launch.py:256:main] process 6806 spawned with command: ['/home/victor/anaconda3/envs/nir/bin/python', '-u', 'opt_my.py', '--local_rank=1']
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
start benchmark
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
model:
[OPTModel(
  (decoder): OPTDecoder(
    (embed_tokens): TPColumnEmbedding()
    (embed_positions): SimpleSplitter(
      (module): OPTLearnedPositionalEmbedding(2050, 2048)
    )
    (final_layer_norm): TPLayerNorm()
    (layers): ModuleList(
      (0-23): 24 x OPTDecoderLayer(
        (self_attn): OPTAttention(
          (k_proj): TPRowLinear()
          (v_proj): TPRowLinear()
          (q_proj): TPRowLinear()
          (out_proj): TPColumnLinear()
        )
        (activation_fn): ReLU()
        (self_attn_layer_norm): TPLayerNorm()
        (fc1): TPRowLinear()
        (fc2): TPColumnLinear()
        (final_layer_norm): TPLayerNorm()
      )
    )
  )
), TPRowLinear()]
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
stop benchmark/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(

                                  time  ...  max_memory_gpu_1
name                                    ...                  
start                     11865.852484  ...          0.000003
generator                 11873.296924  ...          2.651028
max new tokens:256 start  11873.298877  ...          2.651029
max new tokens:256 stop   13861.715980  ...          3.333449

[4 rows x 5 columns]
-------Benchmark results-------
model name: my_opt-1.3b
model size: 4.902, dtype: float32
mean inference time (s): 1988.417
mean throughput (token/s): 1.416
data size: 11, batch size: 11, max len: 64
max new tokens: [256]

inference time (s): 1988.417
throughput (token/s): 1.416

max memory allocated per device for generator (GB):            
    device 0: 2.651
    device 1: 2.651

max memory allocated per device for inference (GB):            
    device 0: 3.333
    device 1: 3.333

max memory allocated per device (GB):            
    device 0: 3.333
    device 1: 3.333
[2025-09-20 14:56:03,587] [INFO] [launch.py:351:main] Process 6805 exits successfully.
[2025-09-20 14:56:03,587] [INFO] [launch.py:351:main] Process 6806 exits successfully.
