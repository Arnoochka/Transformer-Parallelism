[2025-09-24 19:38:15,033] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-24 19:38:18,226] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-09-24 19:38:18,892] [WARNING] [runner.py:220:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-09-24 19:38:18,893] [INFO] [runner.py:610:main] cmd = /home/victor/anaconda3/envs/nir/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None opt_my.py
[2025-09-24 19:38:20,951] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-24 19:38:24,023] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-09-24 19:38:24,687] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1]}
[2025-09-24 19:38:24,687] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=2, node_rank=0
[2025-09-24 19:38:24,688] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})
[2025-09-24 19:38:24,688] [INFO] [launch.py:164:main] dist_world_size=2
[2025-09-24 19:38:24,688] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1
[2025-09-24 19:38:24,688] [INFO] [launch.py:256:main] process 4589 spawned with command: ['/home/victor/anaconda3/envs/nir/bin/python', '-u', 'opt_my.py', '--local_rank=0']
[2025-09-24 19:38:24,691] [INFO] [launch.py:256:main] process 4590 spawned with command: ['/home/victor/anaconda3/envs/nir/bin/python', '-u', 'opt_my.py', '--local_rank=1']
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
start benchmark
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
model:
[OPTModel(
  (decoder): OPTDecoder(
    (embed_tokens): TPColumnEmbedding()
    (embed_positions): SimpleSplitter(
      (module): OPTLearnedPositionalEmbedding(2050, 2048)
    )
    (final_layer_norm): TPLayerNorm()
    (layers): ModuleList(
      (0-23): 24 x OPTDecoderLayer(
        (self_attn): OPTAttention(
          (k_proj): TPRowLinear()
          (v_proj): TPRowLinear()
          (q_proj): TPRowLinear()
          (out_proj): TPColumnLinear()
        )
        (activation_fn): ReLU()
        (self_attn_layer_norm): TPLayerNorm()
        (fc1): TPRowLinear()
        (fc2): TPColumnLinear()
        (final_layer_norm): TPLayerNorm()
      )
    )
  )
), TPRowLinear()]
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
/home/victor/anaconda3/envs/nir/lib/python3.11/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
stop benchmark
                               time  ...  max_memory_gpu_1
name                                 ...                  
start                   6843.134825  ...          0.000003
generator               6850.465831  ...          2.651028
max new tokens:8 start  6850.467842  ...          2.651029
max new tokens:8 stop   6872.769236  ...          2.812009

[4 rows x 5 columns]
-------Benchmark results-------
model name: my_opt-1.3b
model size: 4.902, dtype: float32
mean inference time (s): 22.301
mean throughput (token/s): 3.946
data size: 11, batch size: 11, max len: 64
max new tokens: [8]
    inference time (s): 22.301
    throughput (token/s): 3.946

max memory allocated per device for generator (GB):            
    device 0: 2.651
    device 1: 2.651

max memory allocated per device for inference (GB):            
    device 0: 2.812
    device 1: 2.812

max memory allocated per device (GB):            
    device 0: 2.812
    device 1: 2.812
[2025-09-24 19:39:08,703] [INFO] [launch.py:351:main] Process 4590 exits successfully.
[2025-09-24 19:39:08,703] [INFO] [launch.py:351:main] Process 4589 exits successfully.
